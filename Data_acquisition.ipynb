{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18372d5e",
   "metadata": {},
   "source": [
    "### Part 2: Data Acquisition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f727be4",
   "metadata": {},
   "source": [
    "Below, we filter data from the National Student Survey, as well as from the website Reddit.com. We also import all of the modules we will use throughout the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "5b7fa884",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import json\n",
    "import requests.auth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635fa471",
   "metadata": {},
   "source": [
    "### NSS Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f545115c",
   "metadata": {},
   "source": [
    "The National Student Survey gathers feedback from students concerning student satisfaction in regards to their course, teaching, and other aspects of university. It is collected from final year undergraduate students across UK universities. Multiple other university comparison websites such as \"the Complete University Guide\" reference the NSS, a testament to its reliability.\n",
    "\n",
    "The data is displayed on the NSS website as a series of excel files, with the name of each file being the 'UK Provider Reference Number' of each university. We renamed the files to be used and shifted them to the 'Data' folder of the Report."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a47824",
   "metadata": {},
   "source": [
    "For this project we have chosen to compare LSE to the following universities:\n",
    "\n",
    "- University of Oxford\n",
    "- University College London\n",
    "- Birmingham University\n",
    "- Edinburgh University\n",
    "- Glasgow University\n",
    "- Imperial College London\n",
    "- Kings College London\n",
    "- Manchester University\n",
    "- Norwich University of the Arts\n",
    "- Strathclyde University\n",
    "- Warwick University\n",
    "\n",
    "We chose these universities as they encompass a wide range of different categories; some can be closely compared to LSE, such as UCL, KCL, and Imperial, all in London. Other universities are in the Northern parts of the UK, whilst others are specialised in completely different subjects to LSE (Norwich). We believe this will make comparisons more interesting.\n",
    "\n",
    "\n",
    "We store all of the dataframes (which we clean by removing unnecessary columns and formating correctly)* into a dictionary univ_df.\n",
    "\n",
    "*For example, since the NSS combines student's responses to the Questions into one overall \\\"Positivity Measure\\\", which is the proportion of respondents who gave a positive answer, we only need that, rather than the actual responses to the questions (e.g. Option 1, Option 2, etc.). This does lose some of the n√∫ance to the data, but makes visualisation and understanding the data easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b07b442",
   "metadata": {},
   "outputs": [],
   "source": [
    "university_names = [\n",
    "    \"LSE\",\n",
    "    \"Oxford\",\n",
    "    \"UCL\",\n",
    "    \"Birmingham\",\n",
    "    \"Edinburgh\",\n",
    "    \"Glasgow\",\n",
    "    \"Imperial\",\n",
    "    \"KCL\",\n",
    "    \"Manchester\",\n",
    "    \"Norwich\",\n",
    "    \"Strathclyde\",\n",
    "    \"Warwick\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33836a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#storing all of the university data in a dictionary DataFrame\n",
    "univ_df = {}\n",
    "\n",
    "for university_name in university_names:\n",
    "    file_path = './data/' + university_name + '_dat.xlsx'\n",
    "    df = pd.read_excel(file_path, sheet_name=\"Teaching\", header=3)\n",
    "    \n",
    "    # Drop unnecessary columns\n",
    "    columns_to_drop = [\n",
    "        \"Mode of study\",\n",
    "        \"Suppression reason\",\n",
    "        \"Option 1\",\n",
    "        \"Option 2\",\n",
    "        \"Option 3\",\n",
    "        \"Option 4\",\n",
    "        \"Option 5\",\n",
    "        \"This does not apply to me\",\n",
    "        \"Benchmark (%)\",\n",
    "        \"Difference (ppt)\",\n",
    "        \"Contribution to benchmark (%)\",\n",
    "        \"Materially below benchmark (%)\",\n",
    "        \"Materially above benchmark (%)\",\n",
    "        \"Publication response headcount\",\n",
    "        \"Publication response rate (%)\",\n",
    "        \"Broadly in line with benchmark (%)\"\n",
    "    ]\n",
    "    df_cleaned = df.drop(columns_to_drop, axis=1)\n",
    "    \n",
    "    # Store cleaned dataframe in the dictionary\n",
    "    univ_df[university_name] = df_cleaned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3ff7e8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Level of study</th>\n",
       "      <th>Subject level</th>\n",
       "      <th>Subject code</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Question</th>\n",
       "      <th>Responses</th>\n",
       "      <th>Population</th>\n",
       "      <th>Positivity measure (%)</th>\n",
       "      <th>Standard deviation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>All undergraduates</td>\n",
       "      <td>CAH1</td>\n",
       "      <td>CAH11</td>\n",
       "      <td>Computing</td>\n",
       "      <td>Q01: How good are teaching staff at explaining...</td>\n",
       "      <td>92.8</td>\n",
       "      <td>118.5</td>\n",
       "      <td>80.9</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>All undergraduates</td>\n",
       "      <td>CAH1</td>\n",
       "      <td>CAH11</td>\n",
       "      <td>Computing</td>\n",
       "      <td>Q02: How often do teaching staff make the subj...</td>\n",
       "      <td>92.8</td>\n",
       "      <td>118.5</td>\n",
       "      <td>74.1</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All undergraduates</td>\n",
       "      <td>CAH1</td>\n",
       "      <td>CAH11</td>\n",
       "      <td>Computing</td>\n",
       "      <td>Q03: How often is the course intellectually st...</td>\n",
       "      <td>92.8</td>\n",
       "      <td>118.5</td>\n",
       "      <td>73.0</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>All undergraduates</td>\n",
       "      <td>CAH1</td>\n",
       "      <td>CAH11</td>\n",
       "      <td>Computing</td>\n",
       "      <td>Q04: How often does your course challenge you ...</td>\n",
       "      <td>91.8</td>\n",
       "      <td>118.5</td>\n",
       "      <td>76.6</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>All undergraduates</td>\n",
       "      <td>CAH1</td>\n",
       "      <td>CAH11</td>\n",
       "      <td>Computing</td>\n",
       "      <td>Q05: To what extent have you had the chance to...</td>\n",
       "      <td>92.8</td>\n",
       "      <td>118.5</td>\n",
       "      <td>81.9</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Level of study Subject level Subject code    Subject  \\\n",
       "0  All undergraduates          CAH1        CAH11  Computing   \n",
       "1  All undergraduates          CAH1        CAH11  Computing   \n",
       "2  All undergraduates          CAH1        CAH11  Computing   \n",
       "3  All undergraduates          CAH1        CAH11  Computing   \n",
       "4  All undergraduates          CAH1        CAH11  Computing   \n",
       "\n",
       "                                            Question  Responses  Population  \\\n",
       "0  Q01: How good are teaching staff at explaining...       92.8       118.5   \n",
       "1  Q02: How often do teaching staff make the subj...       92.8       118.5   \n",
       "2  Q03: How often is the course intellectually st...       92.8       118.5   \n",
       "3  Q04: How often does your course challenge you ...       91.8       118.5   \n",
       "4  Q05: To what extent have you had the chance to...       92.8       118.5   \n",
       "\n",
       "   Positivity measure (%)  Standard deviation  \n",
       "0                    80.9                 3.8  \n",
       "1                    74.1                 4.4  \n",
       "2                    73.0                 4.2  \n",
       "3                    76.6                 4.1  \n",
       "4                    81.9                 4.1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "univ_df['Norwich'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af39387d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Level of study</th>\n",
       "      <th>Subject level</th>\n",
       "      <th>Subject code</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Question</th>\n",
       "      <th>Responses</th>\n",
       "      <th>Population</th>\n",
       "      <th>Positivity measure (%)</th>\n",
       "      <th>Standard deviation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>All undergraduates</td>\n",
       "      <td>CAH1</td>\n",
       "      <td>CAH04</td>\n",
       "      <td>Psychology</td>\n",
       "      <td>Q01: How good are teaching staff at explaining...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>All undergraduates</td>\n",
       "      <td>CAH1</td>\n",
       "      <td>CAH04</td>\n",
       "      <td>Psychology</td>\n",
       "      <td>Q02: How often do teaching staff make the subj...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>96.7</td>\n",
       "      <td>6.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All undergraduates</td>\n",
       "      <td>CAH1</td>\n",
       "      <td>CAH04</td>\n",
       "      <td>Psychology</td>\n",
       "      <td>Q03: How often is the course intellectually st...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>All undergraduates</td>\n",
       "      <td>CAH1</td>\n",
       "      <td>CAH04</td>\n",
       "      <td>Psychology</td>\n",
       "      <td>Q04: How often does your course challenge you ...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>All undergraduates</td>\n",
       "      <td>CAH1</td>\n",
       "      <td>CAH04</td>\n",
       "      <td>Psychology</td>\n",
       "      <td>Q05: To what extent have you had the chance to...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>96.7</td>\n",
       "      <td>5.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Level of study Subject level Subject code     Subject  \\\n",
       "0  All undergraduates          CAH1        CAH04  Psychology   \n",
       "1  All undergraduates          CAH1        CAH04  Psychology   \n",
       "2  All undergraduates          CAH1        CAH04  Psychology   \n",
       "3  All undergraduates          CAH1        CAH04  Psychology   \n",
       "4  All undergraduates          CAH1        CAH04  Psychology   \n",
       "\n",
       "                                            Question  Responses  Population  \\\n",
       "0  Q01: How good are teaching staff at explaining...       30.0        30.0   \n",
       "1  Q02: How often do teaching staff make the subj...       30.0        30.0   \n",
       "2  Q03: How often is the course intellectually st...       30.0        30.0   \n",
       "3  Q04: How often does your course challenge you ...       30.0        30.0   \n",
       "4  Q05: To what extent have you had the chance to...       30.0        30.0   \n",
       "\n",
       "   Positivity measure (%)  Standard deviation  \n",
       "0                   100.0                 3.7  \n",
       "1                    96.7                 6.1  \n",
       "2                   100.0                 4.7  \n",
       "3                   100.0                 5.1  \n",
       "4                    96.7                 5.7  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "univ_df['LSE'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3777c50",
   "metadata": {},
   "source": [
    "We store the file using the pickle module as it is the easiest to retrieve in our Report Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df847a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/univ_df.pkl','wb') as pickle_file:\n",
    "    pickle.dump(univ_df, pickle_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca03cb2b",
   "metadata": {},
   "source": [
    "We also want to assess how LSE evolved over the years. The NSS before 2023 takes a different format, where all data is displayed as one large excel file for each year. We took these files straight from the NSS website archives and renamed them to their respective years.\n",
    "\n",
    "Unfortunately, the format and questions of the NSS changed in 2023 and so comparisons between years before 2023 with 2023 cannot be exact. However, we decided to acknowledge this factor, yet still continue with the analysis. The cleaning and merging of these data will be carried out in the Report notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cac83bc",
   "metadata": {},
   "source": [
    "### Reddit Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0648ae4",
   "metadata": {},
   "source": [
    "For the Reddit API data, we decided to focus on the subreddit 'UniUK' that has 151 thousand members and is in the top 1% of communities ranked by size. We noticed few posts directly used the phrase 'student satisfaction' when discussing LSE, which we assumed was due to the informal nature of the site. \n",
    "\n",
    "Instead, we searched for posts that contained the word 'lse'. We retreived the top thirty posts under this search criteria, and stored the 'Post Title', 'Score' (number of 'upvotes' by other redditers) and 'Top Comment' in a pandas data frame 'df'. This dataframe was then saved to a csv file \"Data/reddit_data.csv\" so that it can accessed from any other files, and crucially, so that the data only needs to be fetched from Reddit.com once. Since the contents of the subreddit is likely to change frequently, it would be inefficent to perform effective analysis using realtime data, so we instead stored data from the site on 12/04/2024.\n",
    "\n",
    "We chose to use the website Reddit to acquire data for many reasons. Firstly, their API is easy to use, reliable and openly accessible to the public. This allowed us to effiently access user-generated content without the computational and legal issues that web scraping would risk. Since the type of textual data we are searching for (the general opinion of LSE) is rarely provided in formatted tables online, using an the Reddit API is the best way to acquire and aggregate this information in a structured way.\n",
    "\n",
    "Furthermore, the website has a strong user base for university students or people generally interested in the subject, exemplified by the size of the subreddit 'UniUK'. Not only does this give access to a large amount of data, but the posts are detailed and honest. This is because a significant part of the branding for Reddit is the idea of community, where you are likely to find other users who want contribute to the discussion under the protection of anonymity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9f5d01f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Reddit API Data Collection.\n",
    "Use the API key to request an access token by using the data stored in keys.json.\n",
    "Make an API call to retrive posts from 'UniUK'\n",
    "Store the ddata in a data frame.\n",
    "'''\n",
    "\n",
    "#access keys\n",
    "with open('Data/keys.json') as f:\n",
    "    keys = json.load(f)\n",
    "app_id = keys['reddit']['app_id']\n",
    "app_secret = keys['reddit']['app_secret']\n",
    "username = keys['reddit']['username']\n",
    "password = keys['reddit']['password']\n",
    "\n",
    "#request a token\n",
    "client_auth = requests.auth.HTTPBasicAuth(app_id, app_secret)\n",
    "post_data = {'grant_type': 'password',\n",
    "            'username': username,\n",
    "            'password': password}\n",
    "headers = {'User-Agent': f'new connection lse/0.0.1 by {username}'}\n",
    "r = requests.post('https://www.reddit.com/api/v1/access_token',\n",
    "                    auth=client_auth, data=post_data, headers=headers)\n",
    "access_token = r.json()['access_token']\n",
    "\n",
    "#send a request\n",
    "headers = {\"Authorization\": f\"bearer {access_token}\",\n",
    "'User-Agent': f'lse/0.0.1 by {username}'}\n",
    "\n",
    "r = requests.get(\"https://oauth.reddit.com/r/UniUK/search?q=lse\" \\\n",
    "\"&limit=30&sort=top&restrict_sr=true\", headers=headers)\n",
    "\n",
    "titles = []\n",
    "scores = []\n",
    "top_comments = []\n",
    "\n",
    "#post title, score and top comment\n",
    "for post in r.json()[\"data\"][\"children\"]:\n",
    "    post_title = post[\"data\"][\"title\"]\n",
    "    post_score = post[\"data\"][\"score\"]\n",
    "    post_permalink = post[\"data\"][\"permalink\"]\n",
    "\n",
    "    comments_request = requests.get(f\"https://oauth.reddit.com{post_permalink}.json\", headers=headers)\n",
    "    comments_data = comments_request.json()\n",
    "\n",
    "    if isinstance(comments_data, list) and len(comments_data) > 1:\n",
    "        comments = comments_data[1][\"data\"][\"children\"]\n",
    "        if comments:\n",
    "            top_comment = comments[0][\"data\"][\"body\"]\n",
    "            titles.append(post_title)\n",
    "            scores.append(post_score)\n",
    "            top_comments.append(top_comment)\n",
    "\n",
    "lse_reddit_df = pd.DataFrame({\n",
    "    \"Title\": titles,\n",
    "    \"Score\": scores,\n",
    "    \"Top Comment\": top_comments\n",
    "})\n",
    "\n",
    "#save dataframe to csv file\n",
    "lse_reddit_df.to_csv(\"Data/reddit_data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf260e8",
   "metadata": {},
   "source": [
    "Reddit data collected on King's College London, University College London, and Imperial College London for further data analysis is collected below. When searching for data regarding these universities, the following abbreviations have been used for each university, as they gather more responses and are more commonly used to refer to the above universities online.\n",
    "\n",
    "Kings, UCL, Imperial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "6e641992",
   "metadata": {},
   "outputs": [],
   "source": [
    "#access keys\n",
    "with open('Data/keys.json') as f:\n",
    "    keys = json.load(f)\n",
    "app_id = keys['reddit']['app_id']\n",
    "app_secret = keys['reddit']['app_secret']\n",
    "username = keys['reddit']['username']\n",
    "password = keys['reddit']['password']\n",
    "\n",
    "#request a token\n",
    "client_auth = requests.auth.HTTPBasicAuth(app_id, app_secret)\n",
    "post_data = {'grant_type': 'password',\n",
    "            'username': username,\n",
    "            'password': password}\n",
    "headers = {'User-Agent': f'new connection lse/0.0.1 by {username}'}\n",
    "r = requests.post('https://www.reddit.com/api/v1/access_token',\n",
    "                    auth=client_auth, data=post_data, headers=headers)\n",
    "access_token = r.json()['access_token']\n",
    "\n",
    "#send a request\n",
    "headers = {\"Authorization\": f\"bearer {access_token}\",\n",
    "'User-Agent': f'lse/0.0.1 by {username}'}\n",
    "\n",
    "r = requests.get(\"https://oauth.reddit.com/r/UniUK/search?q=ucl\" \\\n",
    "\"&limit=30&sort=top&restrict_sr=true\", headers=headers)\n",
    "\n",
    "titles = []\n",
    "scores = []\n",
    "top_comments = []\n",
    "\n",
    "#post title, score and top comment\n",
    "for post in r.json()[\"data\"][\"children\"]:\n",
    "    post_title = post[\"data\"][\"title\"]\n",
    "    post_score = post[\"data\"][\"score\"]\n",
    "    post_permalink = post[\"data\"][\"permalink\"]\n",
    "\n",
    "    comments_request = requests.get(f\"https://oauth.reddit.com{post_permalink}.json\", headers=headers)\n",
    "    comments_data = comments_request.json()\n",
    "\n",
    "    if isinstance(comments_data, list) and len(comments_data) > 1:\n",
    "        comments = comments_data[1][\"data\"][\"children\"]\n",
    "        if comments:\n",
    "            top_comment = comments[0][\"data\"][\"body\"]\n",
    "            titles.append(post_title)\n",
    "            scores.append(post_score)\n",
    "            top_comments.append(top_comment)\n",
    "\n",
    "ucl_reddit_df = pd.DataFrame({\n",
    "    \"Title\": titles,\n",
    "    \"Score\": scores,\n",
    "    \"Top Comment\": top_comments\n",
    "})\n",
    "\n",
    "#save dataframe to csv file\n",
    "ucl_reddit_df.to_csv(\"Data/ucl_reddit_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc870bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#access keys\n",
    "with open('Data/keys.json') as f:\n",
    "    keys = json.load(f)\n",
    "app_id = keys['reddit']['app_id']\n",
    "app_secret = keys['reddit']['app_secret']\n",
    "username = keys['reddit']['username']\n",
    "password = keys['reddit']['password']\n",
    "\n",
    "#request a token\n",
    "client_auth = requests.auth.HTTPBasicAuth(app_id, app_secret)\n",
    "post_data = {'grant_type': 'password',\n",
    "            'username': username,\n",
    "            'password': password}\n",
    "headers = {'User-Agent': f'new connection lse/0.0.1 by {username}'}\n",
    "r = requests.post('https://www.reddit.com/api/v1/access_token',\n",
    "                    auth=client_auth, data=post_data, headers=headers)\n",
    "access_token = r.json()['access_token']\n",
    "\n",
    "#send a request\n",
    "headers = {\"Authorization\": f\"bearer {access_token}\",\n",
    "'User-Agent': f'lse/0.0.1 by {username}'}\n",
    "\n",
    "r = requests.get(\"https://oauth.reddit.com/r/UniUK/search?q=kings\" \\\n",
    "\"&limit=30&sort=top&restrict_sr=true\", headers=headers)\n",
    "\n",
    "titles = []\n",
    "scores = []\n",
    "top_comments = []\n",
    "\n",
    "#post title, score and top comment\n",
    "for post in r.json()[\"data\"][\"children\"]:\n",
    "    post_title = post[\"data\"][\"title\"]\n",
    "    post_score = post[\"data\"][\"score\"]\n",
    "    post_permalink = post[\"data\"][\"permalink\"]\n",
    "\n",
    "    comments_request = requests.get(f\"https://oauth.reddit.com{post_permalink}.json\", headers=headers)\n",
    "    comments_data = comments_request.json()\n",
    "\n",
    "    if isinstance(comments_data, list) and len(comments_data) > 1:\n",
    "        comments = comments_data[1][\"data\"][\"children\"]\n",
    "        if comments:\n",
    "            top_comment = comments[0][\"data\"][\"body\"]\n",
    "            titles.append(post_title)\n",
    "            scores.append(post_score)\n",
    "            top_comments.append(top_comment)\n",
    "\n",
    "kings_reddit_df = pd.DataFrame({\n",
    "    \"Title\": titles,\n",
    "    \"Score\": scores,\n",
    "    \"Top Comment\": top_comments\n",
    "})\n",
    "\n",
    "#save dataframe to csv file\n",
    "kings_reddit_df.to_csv(\"Data/kings_reddit_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63d43a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#access keys\n",
    "with open('Data/keys.json') as f:\n",
    "    keys = json.load(f)\n",
    "app_id = keys['reddit']['app_id']\n",
    "app_secret = keys['reddit']['app_secret']\n",
    "username = keys['reddit']['username']\n",
    "password = keys['reddit']['password']\n",
    "\n",
    "#request a token\n",
    "client_auth = requests.auth.HTTPBasicAuth(app_id, app_secret)\n",
    "post_data = {'grant_type': 'password',\n",
    "            'username': username,\n",
    "            'password': password}\n",
    "headers = {'User-Agent': f'new connection lse/0.0.1 by {username}'}\n",
    "r = requests.post('https://www.reddit.com/api/v1/access_token',\n",
    "                    auth=client_auth, data=post_data, headers=headers)\n",
    "access_token = r.json()['access_token']\n",
    "\n",
    "#send a request\n",
    "headers = {\"Authorization\": f\"bearer {access_token}\",\n",
    "'User-Agent': f'lse/0.0.1 by {username}'}\n",
    "\n",
    "r = requests.get(\"https://oauth.reddit.com/r/UniUK/search?q=imperial\" \\\n",
    "\"&limit=30&sort=top&restrict_sr=true\", headers=headers)\n",
    "\n",
    "titles = []\n",
    "scores = []\n",
    "top_comments = []\n",
    "\n",
    "#post title, score and top comment\n",
    "for post in r.json()[\"data\"][\"children\"]:\n",
    "    post_title = post[\"data\"][\"title\"]\n",
    "    post_score = post[\"data\"][\"score\"]\n",
    "    post_permalink = post[\"data\"][\"permalink\"]\n",
    "\n",
    "    comments_request = requests.get(f\"https://oauth.reddit.com{post_permalink}.json\", headers=headers)\n",
    "    comments_data = comments_request.json()\n",
    "\n",
    "    if isinstance(comments_data, list) and len(comments_data) > 1:\n",
    "        comments = comments_data[1][\"data\"][\"children\"]\n",
    "        if comments:\n",
    "            top_comment = comments[0][\"data\"][\"body\"]\n",
    "            titles.append(post_title)\n",
    "            scores.append(post_score)\n",
    "            top_comments.append(top_comment)\n",
    "\n",
    "imperial_reddit_df = pd.DataFrame({\n",
    "    \"Title\": titles,\n",
    "    \"Score\": scores,\n",
    "    \"Top Comment\": top_comments\n",
    "})\n",
    "\n",
    "#save dataframe to csv file\n",
    "imperial_reddit_df.to_csv(\"Data/imperial_reddit_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ceb53b5",
   "metadata": {},
   "source": [
    "To answer the question 'Has student satisfaction improved since COVID-19? (2020-2023)?', we then decided to search the same subreddit 'UniUK' but instead with the key work 'covid'*. Similar to previously, these posts and comments were stored in a csv titled 'covid_reddit_data.csv' in the 'Data' folder. We intended to search on Reddit specifially for LSE student opinions about COVID-19, however very few relevant posts were found. For example, most were referencing a research paper on COVID-19 published by an LSE staff member instead of student opinions on the pandemic. This could be noted as a positive sign that there was few complaints online that students had about LSE during lockdown.\n",
    "\n",
    "We justified only searching the subreddit under the umbrella term 'covid' since we primarily wanted to see if there was an overall impact on student satisfaction for unversity students across the UK, and we could assume this also includes LSE. This also gave us a larger scope of data to collect.\n",
    "\n",
    "*Note: the informal name 'covid' was used to denote the pandemic instead of 'COVID-19' as this generated more search results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8979f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Reddit API Data Collection.\n",
    "Use the API key to request an access token by using the data stored in keys.json.\n",
    "Make an API call to retrive posts from 'UniUK'\n",
    "Store the ddata in a data frame.\n",
    "'''\n",
    "\n",
    "#access keys\n",
    "with open('Data/keys.json') as f:\n",
    "    keys = json.load(f)\n",
    "app_id = keys['reddit']['app_id']\n",
    "app_secret = keys['reddit']['app_secret']\n",
    "username = keys['reddit']['username']\n",
    "password = keys['reddit']['password']\n",
    "\n",
    "#request a token\n",
    "client_auth = requests.auth.HTTPBasicAuth(app_id, app_secret)\n",
    "post_data = {'grant_type': 'password',\n",
    "            'username': username,\n",
    "            'password': password}\n",
    "headers = {'User-Agent': f'new connection lse/0.0.1 by {username}'}\n",
    "r = requests.post('https://www.reddit.com/api/v1/access_token',\n",
    "                    auth=client_auth, data=post_data, headers=headers)\n",
    "access_token = r.json()['access_token']\n",
    "\n",
    "#send a request\n",
    "headers = {\"Authorization\": f\"bearer {access_token}\",\n",
    "'User-Agent': f'lse/0.0.1 by {username}'}\n",
    "\n",
    "r = requests.get(\"https://oauth.reddit.com/r/UniUK/search?q=covid\" \\\n",
    "\"&limit=200&sort=top&restrict_sr=true\", headers=headers)\n",
    "\n",
    "titles = []\n",
    "scores = []\n",
    "top_comments = []\n",
    "\n",
    "#post title, score and top comment\n",
    "for post in r.json()[\"data\"][\"children\"]:\n",
    "    post_title = post[\"data\"][\"title\"]\n",
    "    post_score = post[\"data\"][\"score\"]\n",
    "    post_permalink = post[\"data\"][\"permalink\"]\n",
    "\n",
    "    comments_request = requests.get(f\"https://oauth.reddit.com{post_permalink}.json\", headers=headers)\n",
    "    comments_data = comments_request.json()\n",
    "\n",
    "    if isinstance(comments_data, list) and len(comments_data) > 1:\n",
    "        comments = comments_data[1][\"data\"][\"children\"]\n",
    "        if comments:\n",
    "            top_comment = comments[0][\"data\"][\"body\"]\n",
    "            titles.append(post_title)\n",
    "            scores.append(post_score)\n",
    "            top_comments.append(top_comment)\n",
    "\n",
    "reddit_covid_df = pd.DataFrame({\n",
    "    \"Title\": titles,\n",
    "    \"Score\": scores,\n",
    "    \"Top Comment\": top_comments\n",
    "})\n",
    "\n",
    "#save dataframe to csv file\n",
    "reddit_covid_df.to_csv(\"Data/covid_reddit_data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "0541b8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#below is optimised code, BUT WILL MESS UP YOUR EXISITNG CODE SOPHIE for reddit stuff!! SO lets se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "cf61286b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Reddit API Data Collection.\n",
    "Use the API key to request an access token by using the data stored in keys.json.\n",
    "Make an API call to retrive posts from 'UniUK'\n",
    "Store the data in a data frame.\n",
    "'''\n",
    "\n",
    "def fetch_reddit_data(query, limit):\n",
    "    \n",
    "    with open('Data/keys.json') as f:\n",
    "        keys = json.load(f)\n",
    "    app_id = keys['reddit']['app_id']\n",
    "    app_secret = keys['reddit']['app_secret']\n",
    "    username = keys['reddit']['username']\n",
    "    password = keys['reddit']['password']\n",
    "    \n",
    "    # Request a token\n",
    "    client_auth = requests.auth.HTTPBasicAuth(app_id, app_secret)\n",
    "    post_data = {'grant_type': 'password',\n",
    "                'username': username,\n",
    "                'password': password}\n",
    "    headers = {'User-Agent': f'new connection lse/0.0.1 by {username}'}\n",
    "    r = requests.post('https://www.reddit.com/api/v1/access_token',\n",
    "                        auth=client_auth, data=post_data, headers=headers)\n",
    "    access_token = r.json()['access_token']\n",
    "    \n",
    "    # Send a request\n",
    "    headers = {\"Authorization\": f\"bearer {access_token}\",\n",
    "               'User-Agent': f'lse/0.0.1 by {username}'}\n",
    "    r = requests.get(f\"https://oauth.reddit.com/r/UniUK/search?q={query}\" \\\n",
    "                     f\"&limit={limit}&sort=top&restrict_sr=true\", headers=headers)\n",
    "    \n",
    "    titles = []\n",
    "    scores = []\n",
    "    top_comments = []\n",
    "    \n",
    "    # Post title, score, and top comment\n",
    "    for post in r.json()[\"data\"][\"children\"]:\n",
    "        post_title = post[\"data\"][\"title\"]\n",
    "        post_score = post[\"data\"][\"score\"]\n",
    "        post_permalink = post[\"data\"][\"permalink\"]\n",
    "\n",
    "        comments_request = requests.get(f\"https://oauth.reddit.com{post_permalink}.json\", headers=headers)\n",
    "        comments_data = comments_request.json()\n",
    "\n",
    "        if isinstance(comments_data, list) and len(comments_data) > 1:\n",
    "            comments = comments_data[1][\"data\"][\"children\"]\n",
    "            if comments:\n",
    "                top_comment = comments[0][\"data\"][\"body\"]\n",
    "                titles.append(post_title)\n",
    "                scores.append(post_score)\n",
    "                top_comments.append(top_comment)\n",
    "    \n",
    "    reddit_df = pd.DataFrame({\n",
    "        \"Title\": titles,\n",
    "        \"Score\": scores,\n",
    "        \"Top Comment\": top_comments\n",
    "    })\n",
    "    \n",
    "    # Save dataframe to csv file\n",
    "    reddit_df.to_csv(f\"Data/{query}_reddit_data_c.csv\", index=False)\n",
    "    #ABOVE CODE NEEDS TO BE CHANGED, ITS CURRENTLY SAVING TO AN OFF FILE!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "28375b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_reddit_data('lse', 30)\n",
    "fetch_reddit_data('kings', 30)\n",
    "fetch_reddit_data('ucl', 30)\n",
    "fetch_reddit_data('imperial', 30)\n",
    "fetch_reddit_data('covid', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "5c8ec162",
   "metadata": {},
   "outputs": [],
   "source": [
    "#above code HAS NOT BEEN RAN YET, DO NOT RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f2e062",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
